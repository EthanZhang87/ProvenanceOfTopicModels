title: Random-access memory
id: 21306150
Random access memory RAM is a form of electronic computer memory that can be read and changed in any order typically used to store working data and machine code A random access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory in contrast with other direct access data storage media such as hard disks and magnetic tape where the time required to read and write data items varies significantly depending on their physical locations on the recording medium due to mechanical limitations such as media rotation speeds and arm movement br In today s technology random access memory takes the form of integrated circuit IC chips with MOS metal oxide semiconductor memory cells RAM is normally associated with volatile types of memory where stored information is lost if power is removed The two main types of volatile random access semiconductor memory are static random access memory SRAM and dynamic random access memory DRAM br Non volatile RAM has also been developed and other types of non volatile memories allow random access for read operations but either do not allow write operations or have other kinds of limitations These include most types of ROM and NOR flash memory br The use of semiconductor RAM dates back to when IBM introduced the monolithic single chip bit SP SRAM chip for their System Model computer and Toshiba used discrete DRAM memory cells for its bit Toscal BC electronic calculator both based on bipolar transistors While it offered higher speeds than magnetic core memory bipolar DRAM could not compete with the lower price of the then dominant magnetic core memory Memory based on MOS transistors was developed in the late s and was the basis for all early commercial semiconductor memory The first commercial DRAM IC chip the K Intel was introduced in October Synchronous dynamic random access memory SDRAM later debuted with the Samsung KM SL chip in br br br History br br Early computers used relays mechanical counters or delay lines for main memory functions Ultrasonic delay lines were serial devices which could only reproduce data in the order it was written Drum memory could be expanded at relatively low cost but efficient retrieval of memory items requires knowledge of the physical layout of the drum to optimize speed Latches built out of vacuum tube triodes and later out of discrete transistors were used for smaller and faster memories such as registers Such registers were relatively large and too costly to use for large amounts of data generally only a few dozen or few hundred bits of such memory could be provided br The first practical form of random access memory was the Williams tube starting in It stored data as electrically charged spots on the face of a cathode ray tube Since the electron beam of the CRT could read and write the spots on the tube in any order memory was random access The capacity of the Williams tube was a few hundred to around a thousand bits but it was much smaller faster and more power efficient than using individual vacuum tube latches Developed at the University of Manchester in England the Williams tube provided the medium on which the first electronically stored program was implemented in the Manchester Baby computer which first successfully ran a program on June In fact rather than the Williams tube memory being designed for the Baby the Baby was a testbed to demonstrate the reliability of the memory br Magnetic core memory was invented in and developed up until the mid s It became a widespread form of random access memory relying on an array of magnetized rings By changing the sense of each ring s magnetization data could be stored with one bit stored per ring Since every ring had a combination of address wires to select and read or write it access to any memory location in any sequence was possible Magnetic core memory was the standard form of computer memory system until displaced by solid state MOS metal oxide silicon semiconductor memory in integrated circuits ICs during the early s br Prior to the development of integrated read only memory ROM circuits permanent or read only random access memory was often constructed using diode matrices driven by address decoders or specially wound core rope memory planes br Semiconductor memory began in the s with bipolar memory which used bipolar transistors Although it was faster it could not compete with the lower price of magnetic core memory br br br MOS RAM br The invention of the MOSFET metal oxide semiconductor field effect transistor also known as the MOS transistor by Mohamed M Atalla and Dawon Kahng at Bell Labs in led to the development of metal oxide semiconductor MOS memory by John Schmidt at Fairchild Semiconductor in In addition to higher speeds MOS semiconductor memory was cheaper and consumed less power than magnetic core memory The development of silicon gate MOS integrated circuit MOS IC technology by Federico Faggin at Fairchild in enabled the production of MOS memory chips MOS memory overtook magnetic core memory as the dominant memory technology in the early s br An integrated bipolar static random access memory SRAM was invented by Robert H Norman at Fairchild Semiconductor in It was followed by the development of MOS SRAM by John Schmidt at Fairchild in SRAM became an alternative to magnetic core memory but required six MOS transistors for each bit of data Commercial use of SRAM began in when IBM introduced the SP memory chip for the System Model br Dynamic random access memory DRAM allowed replacement of a or transistor latch circuit by a single transistor for each memory bit greatly increasing memory density at the cost of volatility Data was stored in the tiny capacitance of each transistor and had to be periodically refreshed every few milliseconds before the charge could leak away Toshiba s Toscal BC electronic calculator which was introduced in used a form of capacitive bipolar DRAM storing bit data on discrete memory cells consisting of germanium bipolar transistors and capacitors While it offered higher speeds than magnetic core memory bipolar DRAM could not compete with the lower price of the then dominant magnetic core memory br MOS technology is the basis for modern DRAM In Dr Robert H Dennard at the IBM Thomas J Watson Research Center was working on MOS memory While examining the characteristics of MOS technology he found it was capable of building capacitors and that storing a charge or no charge on the MOS capacitor could represent the and of a bit while the MOS transistor could control writing the charge to the capacitor This led to his development of a single transistor DRAM memory cell In Dennard filed a patent under IBM for a single transistor DRAM memory cell based on MOS technology The first commercial DRAM IC chip was the Intel which was manufactured on an m MOS process with a capacity of kbit and was released in br Synchronous dynamic random access memory SDRAM was developed by Samsung Electronics The first commercial SDRAM chip was the Samsung KM SL which had a capacity of Mbit It was introduced by Samsung in and mass produced in The first commercial DDR SDRAM double data rate SDRAM memory chip was Samsung s Mbit DDR SDRAM chip released in June GDDR graphics DDR is a form of DDR SGRAM synchronous graphics RAM which was first released by Samsung as a Mbit memory chip in br br br Types br The two widely used forms of modern RAM are static RAM SRAM and dynamic RAM DRAM In SRAM a bit of data is stored using the state of a six transistor memory cell typically using six MOSFETs This form of RAM is more expensive to produce but is generally faster and requires less dynamic power than DRAM In modern computers SRAM is often used as cache memory for the CPU DRAM stores a bit of data using a transistor and capacitor pair typically a MOSFET and MOS capacitor respectively which together comprise a DRAM cell The capacitor holds a high or low charge or respectively and the transistor acts as a switch that lets the control circuitry on the chip read the capacitor s state of charge or change it As this form of memory is less expensive to produce than static RAM it is the predominant form of computer memory used in modern computers br Both static and dynamic RAM are considered volatile as their state is lost or reset when power is removed from the system By contrast read only memory ROM stores data by permanently enabling or disabling selected transistors such that the memory cannot be altered Writable variants of ROM such as EEPROM and NOR flash share properties of both ROM and RAM enabling data to persist without power and to be updated without requiring special equipment ECC memory which can be either SRAM or DRAM includes special circuitry to detect and or correct random faults memory errors in the stored data using parity bits or error correction codes br In general the term RAM refers solely to solid state memory devices either DRAM or SRAM and more specifically the main memory in most computers In optical storage the term DVD RAM is somewhat of a misnomer since it is not random access it behaves much like a hard disc drive if somewhat slower Aside unlike CD RW or DVD RW DVD RAM does not need to be erased before reuse br br br Memory cell br br The memory cell is the fundamental building block of computer memory The memory cell is an electronic circuit that stores one bit of binary information and it must be set to store a logic high voltage level and reset to store a logic low voltage level Its value is maintained stored until it is changed by the set reset process The value in the memory cell can be accessed by reading it br In SRAM the memory cell is a type of flip flop circuit usually implemented using FETs This means that SRAM requires very low power when not being accessed but it is expensive and has low storage density br A second type DRAM is based around a capacitor Charging and discharging this capacitor can store a or a in the cell However the charge in this capacitor slowly leaks away and must be refreshed periodically Because of this refresh process DRAM uses more power but it can achieve greater storage densities and lower unit costs compared to SRAM br br br Addressing br To be useful memory cells must be readable and writable Within the RAM device multiplexing and demultiplexing circuitry is used to select memory cells Typically a RAM device has a set of address lines br br br br br A br br br br br br br A br br br br br br br br br br A br br n br br br br br displaystyle A A A n br br and for each combination of bits that may be applied to these lines a set of memory cells are activated Due to this addressing RAM devices virtually always have a memory capacity that is a power of two br Usually several memory cells share the same address For example a bit wide RAM chip has memory cells for each address Often the width of the memory and that of the microprocessor are different for a bit microprocessor eight bit RAM chips would be needed br Often more addresses are needed than can be provided by a device In that case external multiplexors to the device are used to activate the correct device that is being accessed br br br Memory hierarchy br br One can read and over write data in RAM Many computer systems have a memory hierarchy consisting of processor registers on die SRAM caches external caches DRAM paging systems and virtual memory or swap space on a hard drive This entire pool of memory may be referred to as RAM by many developers even though the various subsystems can have very different access times violating the original concept behind the random access term in RAM Even within a hierarchy level such as DRAM the specific row column bank rank channel or interleave organization of the components make the access time variable although not to the extent that access time to rotating storage media or a tape is variable The overall goal of using a memory hierarchy is to obtain the fastest possible average access time while minimizing the total cost of the entire memory system generally the memory hierarchy follows the access time with the fast CPU registers at the top and the slow hard drive at the bottom br In many modern personal computers the RAM comes in an easily upgraded form of modules called memory modules or DRAM modules about the size of a few sticks of chewing gum These can be quickly replaced should they become damaged or when changing needs demand more storage capacity As suggested above smaller amounts of RAM mostly SRAM are also integrated in the CPU and other ICs on the motherboard as well as in hard drives CD ROMs and several other parts of the computer system br br br Other uses of RAM br br In addition to serving as temporary storage and working space for the operating system and applications RAM is used in numerous other ways br br br Virtual memory br br Most modern operating systems employ a method of extending RAM capacity known as virtual memory A portion of the computer s hard drive is set aside for a paging file or a scratch partition and the combination of physical RAM and the paging file form the system s total memory For example if a computer has GB B of RAM and a GB page file the operating system has GB total memory available to it When the system runs low on physical memory it can swap portions of RAM to the paging file to make room for new data as well as to read previously swapped information back into RAM Excessive use of this mechanism results in thrashing and generally hampers overall system performance mainly because hard drives are far slower than RAM br br br RAM disk br br Software can partition a portion of a computer s RAM allowing it to act as a much faster hard drive that is called a RAM disk A RAM disk loses the stored data when the computer is shut down unless memory is arranged to have a standby battery source or changes to the RAM disk are written out to a nonvolatile disk The RAM disk is reloaded from the physical disk upon RAM disk initialization br br br Shadow RAM br Sometimes the contents of a relatively slow ROM chip are copied to read write memory to allow for shorter access times The ROM chip is then disabled while the initialized memory locations are switched in on the same block of addresses often write protected This process sometimes called shadowing is fairly common in both computers and embedded systems br As a common example the BIOS in typical personal computers often has an option called use shadow BIOS or similar When enabled functions that rely on data from the BIOS s ROM instead use DRAM locations most can also toggle shadowing of video card ROM or other ROM sections Depending on the system this may not result in increased performance and may cause incompatibilities For example some hardware may be inaccessible to the operating system if shadow RAM is used On some systems the benefit may be hypothetical because the BIOS is not used after booting in favor of direct hardware access Free memory is reduced by the size of the shadowed ROMs br br br Memory wall br The memory wall is the growing disparity of speed between CPU and the response time of memory known as memory latency outside the CPU chip An important reason for this disparity is the limited communication bandwidth beyond chip boundaries which is also referred to as bandwidth wall From to CPU speed improved at an annual rate of while off chip memory response time only improved at Given these trends it was expected that memory latency would become an overwhelming bottleneck in computer performance br Another reason for the disparity is the enormous increase in the size of memory since the start of the PC revolution in the s Originally PCs contained less than mebibyte of RAM which often had a response time of CPU clock cycle meaning that it required wait states Larger memory units are inherently slower than smaller ones of the same type simply because it takes longer for signals to traverse a larger circuit Constructing a memory unit of many gibibytes with a response time of one clock cycle is difficult or impossible Today s CPUs often still have a mebibyte of wait state cache memory but it resides on the same chip as the CPU cores due to the bandwidth limitations of chip to chip communication It must also be constructed from static RAM which is far more expensive than the dynamic RAM used for larger memories Static RAM also consumes far more power br CPU speed improvements slowed significantly partly due to major physical barriers and partly because current CPU designs have already hit the memory wall in some sense Intel summarized these causes in a document br br First of all as chip geometries shrink and clock frequencies rise the transistor leakage current increases leading to excess power consumption and heat Secondly the advantages of higher clock speeds are in part negated by memory latency since memory access times have not been able to keep pace with increasing clock frequencies Third for certain applications traditional serial architectures are becoming less efficient as processors get faster due to the so called Von Neumann bottleneck further undercutting any gains that frequency increases might otherwise buy In addition partly due to limitations in the means of producing inductance within solid state devices resistance capacitance RC delays in signal transmission are growing as feature sizes shrink imposing an additional bottleneck that frequency increases don t address br The RC delays in signal transmission were also noted in Clock Rate versus IPC The End of the Road for Conventional Microarchitectures which projected a maximum of average annual CPU performance improvement between and br A different concept is the processor memory performance gap which can be addressed by D integrated circuits that reduce the distance between the logic and memory aspects that are further apart in a D chip Memory subsystem design requires a focus on the gap which is widening over time The main method of bridging the gap is the use of caches small amounts of high speed memory that houses recent operations and instructions nearby the processor speeding up the execution of those operations or instructions in cases where they are called upon frequently Multiple levels of caching have been developed to deal with the widening gap and the performance of high speed modern computers relies on evolving caching techniques There can be up to a difference between the growth in speed of processor and the lagging speed of main memory access br Solid state hard drives have continued to increase in speed from Mbit s via SATA in up to GB s via NVMe PCIe in closing the gap between RAM and hard disk speeds although RAM continues to be an order of magnitude faster with single lane DDR capable of GB s and modern GDDR even faster Fast cheap non volatile solid state drives have replaced some functions formerly performed by RAM such as holding certain data for immediate availability in server farms terabyte of SSD storage can be had for while TB of RAM would cost thousands of dollars br br br Timeline br br br SRAM br br br DRAM br br br SDRAM br br br SGRAM and HBM br br br See also br br br br br br External links br Media related to RAM at Wikimedia Commons