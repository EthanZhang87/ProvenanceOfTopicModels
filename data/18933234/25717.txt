title: Regular expression
id: 25717
A regular expression shortened as regex or regexp sometimes referred to as rational expression is a sequence of characters that specifies a match pattern in text Usually such patterns are used by string searching algorithms for find or find and replace operations on strings or for input validation Regular expression techniques are developed in theoretical computer science and formal language theory br The concept of regular expressions began in the s when the American mathematician Stephen Cole Kleene formalized the concept of a regular language They came into common use with Unix text processing utilities Different syntaxes for writing regular expressions have existed since the s one being the POSIX standard and another widely used being the Perl syntax br Regular expressions are used in search engines in search and replace dialogs of word processors and text editors in text processing utilities such as sed and AWK and in lexical analysis Regular expressions are supported in many programming languages Library implementations are often called an engine and many of these are available for reuse br br br History br br Regular expressions originated in when mathematician Stephen Cole Kleene described regular languages using his mathematical notation called regular events These arose in theoretical computer science in the subfields of automata theory models of computation and the description and classification of formal languages motivated by Kleene s attempt to describe early artificial neural networks Kleene introduced it as an alternative to McCulloch Pitts s prehensible but admitted We would welcome any suggestions as to a more descriptive term Other early implementations of pattern matching include the SNOBOL language which did not use regular expressions but instead its own pattern matching constructs br Regular expressions entered popular use from in two uses pattern matching in a text editor and lexical analysis in a compiler Among the first appearances of regular expressions in program form was when Ken Thompson built Kleene s notation into the editor QED as a means to match patterns in text files For speed Thompson implemented regular expression matching by just in time compilation JIT to IBM code on the Compatible Time Sharing System an important early example of JIT compilation He later added this capability to the Unix editor ed which eventually led to the popular search tool grep s use of regular expressions grep is a word derived from the command for regular expression searching in the ed editor g re p meaning Global search for Regular Expression and Print matching lines Around the same time when Thompson developed QED a group of researchers including Douglas T Ross implemented a tool based on regular expressions that is used for lexical analysis in compiler design br Many variations of these original forms of regular expressions were used in Unix programs at Bell Labs in the s including lex sed AWK and expr and in other programs such as vi and Emacs which has its own incompatible syntax and behavior Regexes were subsequently adopted by a wide range of programs with these early forms standardized in the POSIX standard in br In the s the more complicated regexes arose in Perl which originally derived from a regex library written by Henry Spencer who later wrote an implementation for Tcl called Advanced Regular Expressions The Tcl library is a hybrid NFA DFA implementation with improved performance characteristics Software projects that have adopted Spencer s Tcl regular expression implementation include PostgreSQL Perl later expanded on Spencer s original library to add many new features Part of the effort in the design of Raku formerly named Perl is to improve Perl s regex integration and to increase their scope and capabilities to allow the definition of parsing expression grammars The result is a mini language called Raku rules which are used to define Raku grammar as well as provide a tool to programmers in the language These rules maintain existing features of Perl x regexes but also allow BNF style definition of a recursive descent parser via sub rules br The use of regexes in structured information standards for document and database modeling started in the s and expanded in the s when industry standards like ISO SGML precursored by ANSI GCA consolidated The kernel of the structure specification language standards consists of regexes Its use is evident in the DTD element group syntax Prior to the use of regular expressions many search languages allowed simple wildcards for example to match any sequence of characters and to match a single character Relics of this can be found today in the glob syntax for filenames and in the SQL LIKE operator br Starting in Philip Hazel developed PCRE Perl Compatible Regular Expressions which attempts to closely mimic Perl s regex functionality and is used by many modern tools including PHP and Apache HTTP Server br Today regexes are widely supported in programming languages text processing programs particularly lexers advanced text editors and some other programs Regex support is part of the standard library of many programming languages including Java and Python and is built into the syntax of others including Perl and ECMAScript In the late s several companies started to offer hardware FPGA GPU implementations of PCRE compatible regex engines that are faster compared to CPU implementations br br br Patterns br The phrase regular expressions or regexes is often used to mean the specific standard textual syntax for representing patterns for matching text as distinct from the mathematical notation described below Each character in a regular expression that is each character in the string describing its pattern is either a metacharacter having a special meaning or a regular character that has a literal meaning For example in the regex b b is a literal character that matches just b while is a metacharacter that matches every character except a newline Therefore this regex matches for example b or bx or b Together metacharacters and literal characters can be used to identify text of a given pattern or process a number of instances of it Pattern matches may vary from a precise equality to a very general similarity as controlled by the metacharacters For example is a very general pattern a z match all lower case letters from a to z is less general and b is a precise pattern matches just b The metacharacter syntax is designed specifically to represent prescribed targets in a concise and flexible way to direct the automation of text processing of a variety of input data in a form easy to type using a standard ASCII keyboard br A very simple case of a regular expression in this syntax is to locate a word spelled two different ways in a text editor the regular expression seriali sz e matches both serialise and serialize Wildcard characters also achieve this but are more limited in what they can pattern as they have fewer metacharacters and a simple language base br The usual context of wildcard characters is in globbing similar names in a list of files whereas regexes are usually employed in applications that pattern match text strings in general For example the regex t t matches excess whitespace at the beginning or end of a line An advanced regular expression that matches any numeral is d d d eE d br br A regex processor translates a regular expression in the above syntax into an internal representation that can be executed and matched against a string representing the text being searched in One possible approach is the Thompson s construction algorithm to construct a nondeterministic finite automaton NFA which is then made deterministic and the resulting deterministic finite automaton DFA is run on the target text string to recognize substrings that match the regular expression br The picture shows the NFA scheme N s obtained from the regular expression s where s denotes a simpler regular expression in turn which has already been recursively translated to the NFA N s br br br Basic concepts br A regular expression often called a pattern specifies a set of strings required for a particular purpose A simple way to specify a finite set of strings is to list its elements or members However there are often more concise ways for example the set containing the three strings Handel H ndel and Haendel can be specified by the pattern H ae ndel we say that this pattern matches each of the three strings However there can be many ways to write a regular expression for the same set of strings for example H n Han Haen del also specifies the same set of three strings in this example br Most formalisms provide the following operations to construct regular expressions br br Boolean or br br A vertical bar separates alternatives For example gray grey can match gray or grey br Grouping br Parentheses are used to define the scope and precedence of the operators among other uses For example gray grey and gr a e y are equivalent patterns which both describe the set of gray or grey br Quantification br A quantifier after an element such as a token character or group specifies how many times the preceding element is allowed to repeat The most common quantifiers are the question mark the asterisk derived from the Kleene star and the plus sign Kleene plus br br Wildcard br br The wildcard matches any character For example br a b matches any string that contains an a and then any character and then b br a b matches any string that contains an a and then the character b at some later point br These constructions can be combined to form arbitrarily complex expressions much like one can construct arithmetical expressions from numbers and the operations and br The precise syntax for regular expressions varies among tools and with context more detail is given in Syntax br br br Formal language theory br Regular expressions describe regular languages in formal language theory They have the same expressive power as regular grammars br br br Formal definition br Regular expressions consist of constants which denote sets of strings and operator symbols which denote operations over these sets The following definition is standard and found as such in most textbooks on formal language theory Given a finite alphabet the following constants are defined br as regular expressions br br empty set denoting the set br empty string denoting the set containing only the empty string which has no characters at all br literal character a in denoting the set containing only the character a br Given regular expressions R and S the following operations over them are defined br to produce regular expressions br br concatenation RS denotes the set of strings that can be obtained by concatenating a string accepted by R and a string accepted by S in that order For example let R denote ab c and S denote d ef Then RS denotes abd abef cd cef br alternation R S denotes the set union of sets described by R and S For example if R describes ab c and S describes ab d ef expression R S describes ab c d ef br Kleene star R denotes the smallest superset of the set described by R that contains and is closed under string concatenation This is the set of all strings that can be made by concatenating any finite number including zero of strings from the set described by R For example if R denotes R denotes the set of all finite binary strings including the empty string If R denotes ab c R denotes ab c abab abc cab cc ababab abcab br To avoid parentheses it is assumed that the Kleene star has the highest priority followed by concatenation then alternation If there is no ambiguity then parentheses may be omitted For example ab c can be written as abc and a b c can be written as a bc Many textbooks use the symbols or for alternation instead of the vertical bar br Examples br br a b denotes a b bb bbb br a b denotes the set of all strings with no symbols other than a and b including the empty string a b aa ab ba bb aaa br ab c denotes the set of strings starting with a then zero or more b s and finally optionally a c a ac ab abc abb abbc br denotes the set of binary numbers that are multiples of br br br Expressive power and compactness br The formal definition of regular expressions is minimal on purpose and avoids defining and these can be expressed as follows a aa and a a Sometimes the complement operator is added to give a generalized regular expression here Rc matches all strings over that do not match R In principle the complement operator is redundant because it does not grant any more expressive power However it can make a regular expression much more concise eliminating a single complement operator can cause a double exponential blow up of its length br Regular expressions in this sense can express the regular languages exactly the class of languages accepted by deterministic finite automata There is however a significant difference in compactness Some classes of regular languages can only be described by deterministic finite automata whose size grows exponentially in the size of the shortest equivalent regular expressions The standard example here is the languages br Lk consisting of all strings over the alphabet a b whose kth from last letter equals a On the one hand a regular expression describing L is given by br br br br br br a br br b br br br br br br br a br br a br br b br br br a br br b br br br a br br b br br br br displaystyle a mid b a a mid b a mid b a mid b br br br Generalizing this pattern to Lk gives the expression br br br br br br a br br b br br br br br br br a br br br br br br a br br b br br br a br br b br br br br a br br b br br br br br br br k br br br br times br br br br br br br br displaystyle a mid b a underbrace a mid b a mid b cdots a mid b k text times br br br On the other hand it is known that every deterministic finite automaton accepting the language Lk must have at least k states Luckily there is a simple mapping from regular expressions to the more general nondeterministic finite automata NFAs that does not lead to such a blowup in size for this reason NFAs are often used as alternative representations of regular languages NFAs are a simple variation of the type grammars of the Chomsky hierarchy br In the opposite direction there are many languages easily described by a DFA that are not easily described by a regular expression For instance determining the validity of a given ISBN requires computing the modulus of the integer base and can be easily implemented with an state DFA However converting it to a regular expression results in a megabytes file br Given a regular expression Thompson s construction algorithm computes an equivalent nondeterministic finite automaton A conversion in the opposite direction is achieved by Kleene s algorithm br Finally it is worth noting that many real world regular expression engines implement features that cannot be described by the regular expressions in the sense of formal language theory rather they implement regexes See below for more on this br br br Deciding equivalence of regular expressions br As seen in many of the examples above there is more than one way to construct a regular expression to achieve the same results br It is possible to write an algorithm that for two given regular expressions decides whether the described languages are equal the algorithm reduces each expression to a minimal deterministic finite state machine and determines whether they are isomorphic equivalent br Algebraic laws for regular expressions can be obtained using a method by Gischer which is best explained along an example In order to check whether X Y and X Y denote the same regular language for all regular expressions X Y it is necessary and sufficient to check whether the particular regular expressions a b and a b denote the same language over the alphabet a b More generally an equation E F between regular expression terms with variables holds if and only if its instantiation with different variables replaced by different symbol constants holds br Every regular expression can be written solely in terms of the Kleene star and set unions over finite words This is a surprisingly difficult problem As simple as the regular expressions are there is no method to systematically rewrite them to some normal form The lack of axiom in the past led to the star height problem In Dexter Kozen axiomatized regular expressions as a Kleene algebra using equational and Horn clause axioms br Already in Redko had proved that no finite set of purely equational axioms can characterize the algebra of regular languages br br br Syntax br A regex pattern matches a target string The pattern is composed of a sequence of atoms An atom is a single point within the regex pattern which it tries to match to the target string The simplest atom is a literal but grouping parts of the pattern to match an atom will require using as metacharacters Metacharacters help form atoms quantifiers telling how many atoms and whether it is a greedy quantifier or not a logical OR character which offers a set of alternatives and a logical NOT character which negates an atom s existence and backreferences to refer to previous atoms of a completing pattern of atoms A match is made not when all the atoms of the string are matched but rather when all the pattern atoms in the regex have matched The idea is to make a small pattern of characters stand for a large number of possible strings rather than compiling a large list of all the literal possibilities br Depending on the regex processor there are about fourteen metacharacters characters that may or may not have their literal character meaning depending on context or whether they are escaped i e preceded by an escape sequence in this case the backslash Modern and POSIX extended regexes use metacharacters more often than their literal meaning so to avoid backslash osis or leaning toothpick syndrome they have a metacharacter escape to a literal mode starting out however they instead have the four bracketing metacharacters and be primarily literal and escape this usual meaning to become metacharacters Common standards implement both The usual metacharacters are and The usual characters that become metacharacters when escaped are dswDSW and N br br br Delimiters br When entering a regex in a programming language they may be represented as a usual string literal hence usually quoted this is common in C Java and Python for instance where the regex re is entered as re However they are often written with slashes as delimiters as in re for the regex re This originates in ed where is the editor command for searching and an expression re can be used to specify a range of lines matching the pattern which can be combined with other commands on either side most famously g re p as in grep global regex print which is included in most Unix based operating systems such as Linux distributions A similar convention is used in sed where search and replace is given by s re replacement and patterns can be joined with a comma to specify a range of lines as in re re This notation is particularly well known due to its use in Perl where it forms part of the syntax distinct from normal string literals In some cases such as sed and Perl alternative delimiters can be used to avoid collision with contents and to avoid having to escape occurrences of the delimiter character in the contents For example in sed the command s X will replace a with an X using commas as delimiters br br br IEEE POSIX Standard br The IEEE POSIX standard has three sets of compliance BRE Basic Regular Expressions ERE Extended Regular Expressions and SRE Simple Regular Expressions SRE is deprecated in favor of BRE as both provide backward compatibility The subsection below covering the character classes applies to both BRE and ERE br BRE and ERE work together ERE adds and and it removes the need to escape the metacharacters and which are required in BRE Furthermore as long as the POSIX standard syntax for regexes is adhered to there can be and often is additional syntax to serve specific yet POSIX compliant applications Although POSIX leaves some implementation specifics undefined BRE and ERE provide a standard which has since been adopted as the default syntax of many tools where the choice of BRE or ERE modes is usually a supported option For example GNU grep has the following options grep E for ERE and grep G for BRE the default and grep P for Perl regexes br Perl regexes have become a de facto standard having a rich and powerful set of atomic expressions Perl has no basic or extended levels As in POSIX EREs and are treated as metacharacters unless escaped other metacharacters are known to be literal or symbolic based on context alone Additional functionality includes lazy matching backreferences named capture groups and recursive patterns br br br POSIX basic and extended br In the POSIX standard Basic Regular Syntax BRE requires that the metacharacters and be designated and whereas Extended Regular Syntax ERE does not br br Examples br br at matches any three character string ending with at including hat cat bat at at and at starting with a space br hc at matches hat and cat br b at matches all strings matched by at except bat br hc at matches all strings matched by at other than hat and cat br hc at matches hat and cat but only at the beginning of the string or line br hc at matches hat and cat but only at the end of the string or line br matches any single character surrounded by and since the brackets are escaped for example a b and bracket space bracket br s matches s followed by zero or more characters for example s saw seed s w and s h m n mQ br According to Ross Cox the POSIX specification requires ambiguous subexpressions to be handled in a way different from Perl s The committee replaced Perl s rules with one that is simple to explain but the new simple rules are actually more complex to implement they were incompatible with pre existing tooling and made it essentially impossible to define a lazy match see below extension As a result very few programs actually implement the POSIX subexpression rules even when they implement other parts of the POSIX syntax br br br Metacharacters in POSIX extended br The meaning of metacharacters escaped with a backslash is reversed for some characters in the POSIX Extended Regular Expression ERE syntax With this syntax a backslash causes the metacharacter to be treated as a literal character So for example is now and is now Additionally support is removed for n backreferences and the following metacharacters are added br br Examples br br hc at matches at hat and cat br hc at matches at hat cat hhat chat hcat cchchat and so on br hc at matches hat cat hhat chat hcat cchchat and so on but not at br cat dog matches cat or dog br POSIX Extended Regular Expressions can often be used with modern Unix utilities by including the command line flag E br br br Character classes br The character class is the most basic regex concept after a literal match It makes one small sequence of characters match a larger set of characters For example A Z could stand for any uppercase letter in the English alphabet and d could mean any digit Character classes apply to both POSIX levels br When specifying a range of characters such as a Z i e lowercase a to uppercase Z the computer s locale settings determine the contents by the numeric ordering of the character encoding They could store digits in that sequence or the ordering could be abc zABC Z or aAbBcC zZ So the POSIX standard defines a character class which will be known by the regex processor installed Those definitions are in the following table br br POSIX character classes can only be used within bracket expressions For example upper ab matches the uppercase letters and lowercase a and b br An additional non POSIX class understood by some tools is word which is usually defined as alnum plus underscore This reflects the fact that in many programming languages these are the characters that may be used in identifiers The editor Vim further distinguishes word and word head classes using the notation w and h since in many programming languages the characters that can begin an identifier are not the same as those that can occur in other positions numbers are generally excluded so an identifier would look like h w or alpha alnum in POSIX notation br Note that what the POSIX regex standards call character classes are commonly referred to as POSIX character classes in other regex flavors which support them With most other regex flavors the term character class is used to describe what POSIX calls bracket expressions br br br Perl and PCRE br br Because of its expressive power and relative ease of reading many other utilities and programming languages have adopted syntax similar to Perl s for example Java JavaScript Julia Python Ruby Qt Microsoft s NET Framework and XML Schema Some languages and tools such as Boost and PHP support multiple regex flavors Perl derivative regex implementations are not identical and usually implement a subset of features found in Perl released in Perl sometimes does incorporate features initially found in other languages For example Perl implements syntactic extensions originally developed in PCRE and Python br br br Lazy matching br In Python and some other implementations e g Java the three common quantifiers and are greedy by default because they match as many characters as possible The regex including the double quotes applied to the string br br Ganymede he continued is the largest moon in the Solar System br br matches the entire line because the entire line begins and ends with a double quote instead of matching only the first part Ganymede The aforementioned quantifiers may however be made lazy or minimal or reluctant matching as few characters as possible by appending a question mark matches only Ganymede br br br Possessive matching br In Java and Python quantifiers may be made possessive by appending a plus sign which disables backing off in a backtracking engine even if doing so would allow the overall match to succeed While the regex applied to the string br br Ganymede he continued is the largest moon in the Solar System br br matches the entire line the regex does not match at all because consumes the entire input including the final Thus possessive quantifiers are most useful with negated character classes e g which matches Ganymede when applied to the same string br Another common extension serving the same function is atomic grouping which disables backtracking for a parenthesized group The typical syntax is group For example while wi w i matches both wi and wii wi w i only matches wii because the engine is forbidden from backtracking and so cannot try setting the group to w after matching wi br Possessive quantifiers are easier to implement than greedy and lazy quantifiers and are typically more efficient at runtime br br br IETF I Regexp br IETF RFC describes I Regexp An Interoperable Regular Expression Format It specifies a limited subset of regular expression idioms designed to be interoperable i e produce the same effect in a large number of regular expression libraries I Regexp is also limited to matching i e providing a true or false match between a regular expression and a given piece of text Thus it lacks advanced features such as capture groups lookahead and backreferences br br br Patterns for non regular languages br Many features found in virtually all modern regular expression libraries provide an expressive power that exceeds the regular languages For example many implementations allow grouping subexpressions with parentheses and recalling the value they match in the same expression backreferences This means that among other things a pattern can match strings of repeated words like papa or WikiWiki called squares in formal language theory The pattern for these strings is br The language of squares is not regular nor is it context free due to the pumping lemma However pattern matching with an unbounded number of backreferences as supported by numerous modern tools is still context sensitive The general problem of matching any number of backreferences is NP complete and the execution time for known algorithms grows exponentially by the number of backreference groups used br However many tools libraries and engines that provide such constructions still use the term regular expression for their patterns This has led to a nomenclature where the term regular expression has different meanings in formal language theory and pattern matching For this reason some people have taken to using the term regex regexp or simply pattern to describe the latter Larry Wall author of the Perl programming language writes in an essay about the design of Raku br br Regular expressions are only marginally related to real regular expressions Nevertheless the term has grown with the capabilities of our pattern matching engines so I m not going to try to fight linguistic necessity here I will however generally call them regexes or regexen when I m in an Anglo Saxon mood br br br Assertions br br Other features not found in describing regular languages include assertions These include the ubiquitous and used since at least as well as some more sophisticated extensions like lookaround that appeared in Lookarounds define the surrounding of a match and do not spill into the match itself a feature only relevant for the use case of string searching Some of them can be simulated in a regular language by treating the surroundings as a part of the language as well br The look ahead assertions and have been attested since at least starting with Perl The look behind assertions and are attested since in a commit by Ilya Zakharevich to Perl br br br Implementations and running times br There are at least three different algorithms that decide whether and how a given regex matches a string br The oldest and fastest relies on a result in formal language theory that allows every nondeterministic finite automaton NFA to be transformed into a deterministic finite automaton DFA The DFA can be constructed explicitly and then run on the resulting input string one symbol at a time Constructing the DFA for a regular expression of size m has the time and memory cost of O m but it can be run on a string of size n in time O n Note that the size of the expression is the size after abbreviations such as numeric quantifiers have been expanded br An alternative approach is to simulate the NFA directly essentially building each DFA state on demand and then discarding it at the next step This keeps the DFA implicit and avoids the exponential construction cost but running cost rises to O mn The explicit approach is called the DFA algorithm and the implicit approach the NFA algorithm Adding caching to the NFA algorithm is often called the lazy DFA algorithm or just the DFA algorithm without making a distinction These algorithms are fast but using them for recalling grouped subexpressions lazy quantification and similar features is tricky Modern implementations include the re re sregex family based on Cox s code br The third algorithm is to match the pattern against the input string by backtracking This algorithm is commonly called NFA but this terminology can be confusing Its running time can be exponential which simple implementations exhibit when matching against expressions like a aa b that contain both alternation and unbounded quantification and force the algorithm to consider an exponentially increasing number of sub cases This behavior can cause a security problem called Regular expression Denial of Service ReDoS br Although backtracking implementations only give an exponential guarantee in the worst case they provide much greater flexibility and expressive power For example any implementation which allows the use of backreferences or implements the various extensions introduced by Perl must include some kind of backtracking Some implementations try to provide the best of both algorithms by first running a fast DFA algorithm and revert to a potentially slower backtracking algorithm only when a backreference is encountered during the match GNU grep and the underlying gnulib DFA uses such a strategy br Sublinear runtime algorithms have been achieved using Boyer Moore BM based algorithms and related DFA optimization techniques such as the reverse scan GNU grep which supports a wide variety of POSIX syntaxes and extensions uses BM for a first pass prefiltering and then uses an implicit DFA Wu agrep which implements approximate matching combines the prefiltering into the DFA in BDM backward DAWG matching NR grep s BNDM extends the BDM technique with Shift Or bit level parallelism br A few theoretical alternatives to backtracking for backreferences exist and their exponents are tamer in that they are only related to the number of backreferences a fixed property of some regexp languages such as POSIX One naive method that duplicates a non backtracking NFA for each backreference note has a complexity of br br br br br br O br br br br br n br br br k br br br br br br br br displaystyle mathrm O n k br br time and br br br br br br O br br br br br n br br br k br br br br br br br br displaystyle mathrm O n k br br space for a haystack of length n and k backreferences in the RegExp A very recent theoretical work based on memory automata gives a tighter bound based on active variable nodes used and a polynomial possibility for some backreferenced regexps br br br Unicode br In theoretical terms any token set can be matched by regular expressions as long as it is pre defined In terms of historical implementations regexes were originally written to use ASCII characters as their token set though regex libraries have supported numerous other character sets Many modern regex engines offer at least some support for Unicode In most respects it makes no difference what the character set is but some issues do arise when extending regexes to support Unicode br br Supported encoding Some regex libraries expect to work on some particular encoding instead of on abstract Unicode characters Many of these require the UTF encoding while others might expect UTF or UTF In contrast Perl and Java are agnostic on encodings instead operating on decoded characters internally br Supported Unicode range Many regex engines support only the Basic Multilingual Plane that is the characters which can be encoded with only bits Currently as of only a few regex engines e g Perl s and Java s can handle the full bit Unicode range br Extending ASCII oriented constructs to Unicode For example in ASCII based implementations character ranges of the form x y are valid wherever x and y have code points in the range x x F and codepoint x codepoint y The natural extension of such character ranges to Unicode would simply change the requirement that the endpoints lie in x x F to the requirement that they lie in x x FFFF However in practice this is often not the case Some implementations such as that of gawk do not allow character ranges to cross Unicode blocks A range like x x F is valid since both endpoints fall within the Basic Latin block as is x x since both endpoints fall within the Armenian block but a range like x x is invalid since it includes multiple Unicode blocks Other engines such as that of the Vim editor allow block crossing but the character values must not be more than apart br Case insensitivity Some case insensitivity flags affect only the ASCII characters Other flags affect all characters Some engines have two different flags one for ASCII the other for Unicode Exactly which characters belong to the POSIX classes also varies br Cousins of case insensitivity As ASCII has case distinction case insensitivity became a logical feature in text searching Unicode introduced alphabetic scripts without case like Devanagari For these case sensitivity is not applicable For scripts like Chinese another distinction seems logical between traditional and simplified In Arabic scripts insensitivity to initial medial final and isolated position may be desired In Japanese insensitivity between hiragana and katakana is sometimes useful br Normalization Unicode has combining characters Like old typewriters plain base characters white spaces punctuation characters symbols digits or letters can be followed by one or more non spacing symbols usually diacritics like accent marks modifying letters to form a single printable character but Unicode also provides a limited set of precomposed characters i e characters that already include one or more combining characters A sequence of a base character combining characters should be matched with the identical single precomposed character only some of these combining sequences can be precomposed into a single Unicode character but infinitely many other combining sequences are possible in Unicode and needed for various languages using one or more combining characters after an initial base character these combining sequences may include a base character or combining characters partially precomposed but not necessarily in canonical order and not necessarily using the canonical precompositions The process of standardizing sequences of a base character combining characters by decomposing these canonically equivalent sequences before reordering them into canonical order and optionally recomposing some combining characters into the leading base character is called normalization br New control codes Unicode introduced amongst others byte order marks and text direction markers These codes might have to be dealt with in a special way br Introduction of character classes for Unicode blocks scripts and numerous other character properties Block properties are much less useful than script properties because a block can have code points from several different scripts and a script can have code points from several different blocks In Perl and the java util regex library properties of the form p InX or p Block X match characters in block X and P InX or P Block X matches code points not in that block Similarly p Armenian p IsArmenian or p Script Armenian matches any character in the Armenian script In general p X matches any character with either the binary property X or the general category X For example p Lu p Uppercase Letter or p GC Lu matches any uppercase letter Binary properties that are not general categories include p White Space p Alphabetic p Math and p Dash Examples of non binary properties are p Bidi Class Right to Left p Word Break A Letter and p Numeric Value br br br Language support br Most general purpose programming languages support regex capabilities either natively or via libraries Comprehensive support is included in br br br Uses br br Regexes are useful in a wide variety of text processing tasks and more generally string processing where the data need not be textual Common applications include data validation data scraping especially web scraping data wrangling simple parsing the production of syntax highlighting systems and many other tasks br While regexes would be useful on Internet search engines processing them across the entire database could consume excessive computer resources depending on the complexity and design of the regex Although in many cases system administrators can run regex based queries internally most search engines do not offer regex support to the public Notable exceptions include Google Code Search and Exalead However Google Code Search was shut down in January br br br Examples br The specific syntax rules vary depending on the specific implementation programming language or library in use Additionally the functionality of regex implementations can vary between versions br Because regexes can be difficult to both explain and understand without examples interactive websites for testing regexes are a useful resource for learning regexes by experimentation br This section provides a basic description of some of the properties of regexes by way of illustration br The following conventions are used in the examples br br metacharacter s the metacharacters column specifies the regex syntax being demonstrated br m indicates a regex match operation in Perl br s indicates a regex substitution operation in Perl br br Also worth noting is that these regexes are all Perl like syntax Standard POSIX regular expressions are different br Unless otherwise indicated the following examples conform to the Perl programming language release January This means that other implementations may lack support for some parts of the syntax shown here e g basic vs extended regex vs or lack of d instead of POSIX digit br The syntax and conventions used in these examples coincide with that of other programming environments as well br br br Induction br br Regular expressions can often be created induced or learned based on a set of example strings This is known as the induction of regular languages and is part of the general problem of grammar induction in computational learning theory Formally given examples of strings in a regular language and perhaps also given examples of strings not in that regular language it is possible to induce a grammar for the language i e a regular expression that generates that language Not all regular languages can be induced in this way see language identification in the limit but many can For example the set of examples and negative set of counterexamples can be used to induce the regular expression followed by zero or more s br br br See also br Comparison of regular expression engines br Extended Backus Naur form br Matching wildcards br Regular tree grammar br Thompson s construction converts a regular expression into an equivalent nondeterministic finite automaton NFA br br br Notes br br br br br br External links br br Media related to Regex at Wikimedia Commons br Regular Expressions at Curlie br ISO IEC Information technology Portable Operating System Interface POSIX Part Shell and Utilities br ISO IEC Information technology Portable Operating System Interface POSIX Part System Interfaces br ISO IEC Information technology Portable Operating System Interface POSIX Part System Interfaces br ISO IEC IEEE Information technology Portable Operating System Interface POSIX Base Specifications Issue br Regular Expression IEEE Std Open Group