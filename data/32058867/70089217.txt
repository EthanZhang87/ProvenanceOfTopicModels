title: Facebook content management controversies
id: 70089217
Facebook or Meta Platforms has been criticized for its management of various content on posts photos and entire groups and profiles This includes but is not limited to allowing violent content including content related to war crimes and not limiting the spread of fake news and COVID misinformation on their platform as well as allowing incitement of violence against multiple groups br br br Intellectual property infringement br Facebook has been criticized for having lax enforcement of third party copyrights for videos uploaded to the service In some Facebook pages were accused of plagiarizing videos from YouTube users and re posting them as their own content using Facebook s video platform and in some cases achieving higher levels of engagement and views than the original YouTube posts Videos hosted by Facebook are given a higher priority and prominence within the platform and its user experience including direct embedding within the News Feed and pages giving a disadvantage to posting it as a link to the original external source In August Facebook announced a video matching technology aiming to identify reposted videos and also stated its intention to improve its procedures to remove infringing content faster In April Facebook implemented a feature known as Rights Manager which allows rights holders to manage and restrict the upload of their content onto the service by third parties br br br Violent content br In Facebook was criticized for allowing users to upload and share videos depicting violent content including clips of people being decapitated Having previously refused to delete such clips under the guideline that users have the right to depict the world in which we live Facebook changed its stance in May announcing that it would remove reported videos while evaluating its policy The following October Facebook stated that it would allow graphic videos on the platform as long as the intention of the video was to condemn not glorify the acts depicted further stating that Sometimes those experiences and issues involve graphic content that is of public interest or concern such as human rights abuses acts of terrorism and other violence When people share this type of graphic content it is often to condemn it If it is being shared for sadistic pleasure or to celebrate violence Facebook removes it However Facebook once again received criticism with the Family Online Safety Institute saying that such videos crossed a line and can potentially cause psychological damage among young Facebook users and then Prime Minister of the United Kingdom David Cameron calling the decision irresponsible citing the same concerns regarding young users Two days later Facebook removed a video of a beheading following worldwide outrage and while acknowledging its commitment to allowing people to upload gory material for the purpose of condemnation it also stated that it would be further strengthening its enforcement to prevent glorification The company s policies were also criticized as part of these developments with some drawing particular attention to Facebook s permission of graphic content but potential removal of breastfeeding images In January Facebook announced that new warnings would be displayed on graphic content requiring users to explicitly confirm that they wish to see the material br br br War crimes br Facebook has been criticized for failing to take down violent content depicting war crimes in Libya A investigation by the BBC found evidence of alleged war crimes in Libya being widely shared on Facebook and YouTube The BBC found images and videos on social media of the bodies of fighters and civilians being desecrated by fighters from the self styled Libyan National Army The force led by General Khalifa Haftar controls a swathe of territory in the east of Libya and is trying to seize the capital Tripoli BBC Arabic found almost one hundred images and videos from Libya shared on Facebook and YouTube in violation of their companies guidelines The UK Foreign Office said it took the allegations extremely seriously and is concerned about the impact the recent violence is having on the civilian population br In a Facebook video of Libyan National Army LNA special forces commander Mahmoud al Werfalli was uploaded showing him shooting dead three captured fighters The video was then shared on YouTube over ten thousand times The International Criminal Court used it as evidence to indict al Werfalli for the war crime of murder The BBC found the original video was still on Facebook years after his indictment and also discovered videos showing the bodies of civilians being desecrated These were taken in Ganfouda a district of Benghazi which was under siege by the LNA between and More than people including dozens of children died during the siege A video uncovered by BBC Arabic showed soldiers mocking a pile of corpses of dead civilians and trampling on bodies Among them was a year old woman Alia Hamza Her son Ali Hamza had five family members killed in Ganfouda br Ali Hamza told BBC Arabic I sent links to lawyers to send to the ICC in the Hague against Khalifa Haftar and his military commanders regarding the massacres of civilians said Hamza In the video the LNA soldiers label the civilians as terrorists Human rights lawyer and war crimes specialist Rodney Dixon QC reviewed the evidence BBC Arabic found If groups are using those platforms to propagate their campaigns then those platforms should seriously look at their role because they could then be assisting in that process of further crimes being committed he said After presenting our findings to Facebook they removed all the videos that show a suspected war crime taking place However they opted not to suspend any of the accounts which we found linked to the images Erin Saltman Facebook s policy manager for counterterrorism in Europe Middle East and Africa told BBC Arabic Sometimes there are very conflicting narratives of whether or not the victim is a terrorist or whether it s a civilian over who s committing that act we cannot be the pure arbiters of truth But Facebook and YouTube s own community guidelines explicitly prohibit content that promotes or depicts acts of violence br br br Facebook Live br Facebook Live introduced in August for celebrities and gradually rolled out for regular users starting in January lets users broadcast live videos with Facebook s intention for the feature to be presenting public events or private celebrations However the feature has been used to record multiple crimes deaths and violent incidents causing significant media attention br Facebook has received criticism for not removing videos faster and Facebook Live has been described as a monster Facebook cannot tame and a gruesome crime scene for murders In response CEO Mark Zuckerberg announced in May that the company would hire moderators to review content and invest in tools to remove videos faster br br br Pro anorexia groups br In Facebook was criticized for hosting groups dedicated to promoting anorexia The groups promoted dramatic weight loss programs shared extreme diet tips and posted pictures of emaciated girls under Thinspiration headlines Members reported having switched to Facebook from Myspace another social networking service due to a perceived higher level of safety and intimacy at Facebook In a statement to BBC News a Facebook spokesperson stated that Many Facebook groups relate to controversial topics this alone is not a reason to disable a group In cases where content is reported and found to violate the site s terms of use Facebook will remove it br br br Pro mafia groups case br In Italy in the discovery of pro mafia groups one of them claiming Bernardo Provenzano s sainthood caused an alert in the country and brought the government to rapidly issue a law that would force Internet service providers to deny access to entire websites in case of refused removal of illegal contents The amendment was passed by the Italian Senate and now needs to be passed unchanged by the Chamber of Deputies to become effective br Facebook criticized the government s efforts telling Bloomberg that it would be like closing an entire railway network just because of offensive graffiti at one station and that Facebook would always remove any content promoting violence and already had a takedown procedure in place br br br Trolling br On March The Today Show ran a segment detailing the deaths of three separate adolescent girls and trolls subsequent reactions to their deaths Shortly after the suicide of high school student Alexis Pilkington anonymous posters began trolling for reactions across various message boards referring to Pilkington as a suicidal CUSS and posting graphic images on her Facebook memorial page The segment also included an expos of a accident in which an eighteen year old student out for a drive fatally crashed her father s car into a highway pylon trolls emailed her grieving family the leaked pictures of her mutilated corpse br There have been cases where Facebook trolls were jailed for their communications on Facebook particularly memorial pages In Autumn Colm Coss of Ardwick Britain was sentenced to weeks in jail under s of the Communications Act of Great Britain for malicious communications for leaving messages deemed obscene and hurtful on Facebook memorial pages br In April Bradley Paul Hampson was sentenced to three years in jail after pleading guilty to two counts of using a carriage service the Internet to cause offense for posts on Facebook memorial pages and one count each of distributing and possessing child pornography when he posted images on the memorial pages of the deceased with phalluses superimposed alongside phrases such as Woot I m dead br br br Rape pages br A series of pro rape and rape joke content on Facebook drew attention from the media and women s groups Rape Is No Joke RINJ a group opposing the pages argued that removing pro rape pages from Facebook and other social media was not a violation of free speech in the context of Article of the Universal Declaration of Human Rights and the concepts recognized in international human rights law in the International Covenant on Civil and Political Rights br RINJ repeatedly challenged Facebook to remove the rape pages RINJ then turned to advertisers on Facebook telling them not to let their advertising be posted on Facebook s rape pages br Following a campaign that involved the participation of Women Action and the Media the Everyday Sexism Project and the activist Soraya Chemaly who were among advocacy groups Facebook agreed to update its policy on hate speech The campaign highlighted content that promoted domestic and sexual violence against women and used over tweets and more than emails to create outcomes such as the withdrawal of advertising from Facebook by companies including Nissan UK House of Burlesque and Nationwide UK The social media website initially responded by stating that While it may be vulgar and offensive distasteful content on its own does not violate our policies but then agreed to take action on May after it had become clear that our systems to identify and remove hate speech have failed to work as effectively as we would like particularly around issues of gender based hate br br br Child abuse images br In June the UK National Society for the Prevention of Cruelty to Children raised concerns about Facebook s apparent refusal when asked to remove controversial video material which allegedly showed a baby in emotional distress br In March BBC News reported in an investigation that Facebook only removed of the groups and posts it had reported for containing child exploitation images The BBC had been granted an interview with Facebook policy director Simon Milner under the condition that they provide evidence of the activity However when presented with the images Facebook canceled the interview and told the BBC that it had been reported to the National Crime Agency for illegally distributing child exploitation images the NCA could not confirm whether the BBC was actually being investigated Milner later stated to the BBC that the investigation had exposed flaws in its image moderation process that have since been addressed and that all of the reported content was removed from the service br According to data from the National Center for Missing Exploited Children in there have been million reported incidents of child sexual abuse material on Facebook This accounted for of total incidents recorded by the organization while Google accounted for half a million incidents Snapchat for and Twitter for br br br Objectification of women br In July GMA News reported that a number of secret Facebook groups that had been engaging in illegal activity of sharing obscene photos of women had been exposed with the Philippine National Bureau of Investigation warning group members of the possibility of being liable for violating child pornography and anti voyeurism laws Facebook stated that it would remove the groups as violations of its community guidelines A few days later GMA News had an interview with one of the female victims targeted by one of the groups who stated that she received friend requests from strangers and inappropriate messages After reporting to authorities the Philippine National Police s anti cybercrime unit promised to take action in finding the accounts responsible Senator Risa Hontiveros responded to the incidents with the proposal of a law that would impose stiff penalties on such group members stating that These people have no right to enjoy our internet freedom only to abuse our women and children We will not allow them to shame our young women suppress their right to express themselves through social media and contribute to a culture of misogyny and hate br br br Violation of Palestinian Human Rights br According to the study commissioned by Meta and carried out by Business for Social Responsibility BSR Facebook and Instagram s policies during Israeli attacks on Gaza Strip in harmed the fundamental human rights of Palestinians The social media giant had denied Palestinian users their freedom of expression by erroneously removing their content BSR s report is yet another indictment of the company s ability to police its global public square and to balance freedom of expression against the potential for harm in a tense international context br br br Anti Semitism br br Facebook has been suspected of having a double standard when it comes to pages and posts regarding the Arab Israeli conflict When it comes to alleged incitement Facebook has been accused of being unfair removing only posts and pages that attack Palestinians while turning a blind eye to similar posts that are violently antisemitic The NGO Shurat Hadin Israel Law Center conducted an experiment over the incitement issue which sought to expose what it viewed as double standards regarding anti Israel sentiment vis a vis the simultaneous launch of two Facebook pages Stop Palestinians and Stop Israel Following the launch of the two nearly identical pages the NGO posted hateful content simultaneously on both pages Next Shurat Hadin reported both faux incitement pages to Facebook to see which if either would be removed According to them despite featuring nearly identical content only one was removed from the online platform They said the page inciting against Palestinians was closed by Facebook on the same day that it was reported for containing credible threat of violence which violated our Facebook s community standards but not the page inciting against Israelis Shurat Hadin said that Facebook claimed that this page was not in violation of Facebook s rules Shurat Hadin s staged anti Israel group Stop Israel still remains active on Facebook ProPublica stated in September that a website was able to target ads at Facebook users who were interested in how to burn Jew and Jew hater Facebook removed the categories and said it would try to stop them from appearing to potential advertisers br In March Facebook subsidiary Instagram declined to remove an anti semitic image posted by right wing conspiracy theorist Alex Jones saying that it did not violate their community standards br br br Incitement of violence against Israelis br Facebook has been accused of being a public platform that is used to incite violence In October Israelis claimed that Facebook was ignoring Palestinian incitement on its platform and filed a class action suit demanding that Facebook remove all posts containing incitement to murder Jews br Israeli politicians have complained that Facebook does not comply or assist with requests from the police for tracking and reporting individuals when they share their intent to kill or commit any other act of violence on their Facebook pages In June following the murder of Hallel Ariel by a terrorist who posted on Facebook Israeli Minister of Public Security Gilad Erdan charged that Facebook which has brought a positive revolution to the world has become a monster The dialogue the incitement the lies of the young Palestinian generation are happening on the Facebook platform Erdan accused Facebook of sabotaging the work of Israeli police and refusing to cooperate when Israel police turns to the site for assistance It also sets a very high bar for removing inciting content br In July a civil action for billion in damages was filed in the United States District Court for the Southern District of New York on behalf of the victims and family members of four Israeli Americans and one US citizen killed by Hamas militants since June The victims and plaintiffs in the case are the families of Yaakov Naftali Fraenkel a year old who was kidnapped and murdered by Hamas operatives in Taylor Force a year old American MBA student and US Army veteran killed in a stabbing spree in Jaffa in Chaya Braun a three month old thrown from her stroller and slammed into the pavement when a Hamas attacker drove his car into a light rail station in Jerusalem in an October year old Richard Lakin who was killed in the October shooting and stabbing attack on a Jerusalem bus and Menachem Mendel Rivkin who was seriously wounded in a January stabbing attack in Jerusalem The plaintiffs claimed that Facebook knowingly provided its social media platform and communication services to Hamas in violation of provisions of US Anti Terrorism laws which prohibits US businesses from providing any material support including services to designated terrorist groups and their leaders The government of the United States has designated Hamas as a Foreign Terrorist Organization as defined by US law The suit claims that Hamas used and relied on Facebook s online social network platform and communications services to facilitate and carry out its terrorist activity including the terrorist attacks in which Hamas murdered and injured the victims and their families in this case The legal claim was rejected the court found that Facebook and other social media companies are not considered to be the publishers of material users post when digital tools used by the company match content with what the tool identifies as interested consumers br In August Israel s security service the Shin Bet reported that it had arrested nine Palestinians who had been recruited by the Lebanon based Hezbollah terrorist organization Operatives of Hezbollah in Lebanon and Gaza Strip recruited residents of the West Bank Gaza and Israel through Facebook and other social media sites After recruiting cell leaders on Facebook Hezbollah and the recruits used encrypted communications to avoid detection and the leaders continued to recruit other members The terror cells received Hezbollah funding and planned to conduct suicide bombings and ambushes and had begun preparing explosive devices for attacks said the security service which claimed credit for preventing the attacks The Shin Bet said it also detected multiple attempts by Hezbollah to recruit Israeli Arabs through a Facebook profile br On October singer and internet personality Dalal Abu Amneh was arrested by the Israeli Police for allegedly promoting hate speech and inciting violence on social media following a massacre perpetrated by Hamas on October br In legislation was being prepared in Israel allowing fines of shekels for Facebook and other social media like Twitter and YouTube for every post inciting or praising terrorism that is not removed within hours and could possibly lead to further acts of terrorism br br br Countermeasure efforts br In June Facebook published a blog post offering insights into how it detects and combats terrorism content The company claimed that the majority of the terrorism accounts that are found are discovered by Facebook itself while it reviews reports of terrorism content urgently and in cases of imminent harm promptly inform authorities It also develops new tools to aid in its efforts including the use of artificial intelligence to match terrorist images and videos detecting when content is shared across related accounts and developing technologies to stop repeat offenders The company stated that it has people dedicated to terrorism countermeasures and works with governments and industries in an effort to curb terrorist propaganda Its blog post stated that We want Facebook to be a hostile place for terrorists br br br Employee data leak br In June The Guardian reported that a software bug had exposed the personal details of Facebook workers involved in reviewing and removing terrorism content by displaying their profiles in the Activity logs of Facebook groups related to terrorism efforts In Facebook s Dublin Ireland headquarters six individuals were determined to be high priority victims of the error after the company concluded that their profiles were likely viewed by potential terrorists in groups such as ISIS Hezbollah and the Kurdistan Workers Party The bug itself discovered in November and fixed two weeks later was active for one month and had also been retroactively exposing censored personal accounts from August One affected worker had fled Ireland gone into hiding and only returned to Ireland after five months due to a lack of money Suffering from psychological distress he filed a legal claim against Facebook and CPL Resources an outsourcing company seeking compensation A Facebook spokesperson stated that Our investigation found that only a small fraction of the names were likely viewed and we never had evidence of any threat to the people impacted or their families as a result of this matter and Craig D Souza Facebook s head of global investigations said Keep in mind that when the person sees your name on the list it was in their activity log which contains a lot of information there is a good chance that they associate you with another admin of the group or a hacker Facebook offered to install a home alarm monitoring system provide transport to and from work and counseling through its employee assistance program As a result of the data leak Facebook is reportedly testing the use of alternative administrative accounts for workers reviewing content rather than requiring workers to sign in with their personal profiles br br br Fake news br br Facebook has been criticized for not doing enough to limit the spread of fake news stories on their site especially after the United States presidential election which some have claimed Donald Trump would not have won if Facebook had not helped spread what they claim to have been fake stories that were biased in his favor At a conference called Techonomy Mark Zuckerberg stated in regards to Donald Trump There s a profound lack of empathy in asserting that the only reason why someone could have voted the way that they did is because they saw some fake news Zuckerberg affirmed the idea that people do not stray from their own ideals and political leanings He stated I don t know what to do about that and When we started the north star for us was We re building a safe community br Zuckerberg has also been quoted in his own Facebook post Of all the content on Facebook more than percent of what people see is authentic In addition The Pew Research Center stated that of Americans obtain some or all of their news on social media the bulk of it from Facebook The former editor at Facebook leaked inflammatory information about the websites algorithm s pointing to certain falsehoods and bias by the news created within Facebook Although Facebook initially denied claims of issues with fake new stories and their algorithms they fired the entire trending team involved with a fake news story about Megyn Kelly being a closeted liberal br In Mark Zuckerberg began to take steps to eliminate the prevalence of fake news on Facebook as a result of criticisms of Facebook s influence on the presidential election Facebook initially partnered with ABC News the Associated Press FactCheck org Snopes and PolitiFact for its fact checking initiative as of it had over fact checking partners across the world including The Weekly Standard A May review by The Guardian found that Facebook s fact checking initiatives of partnering with third party fact checkers and publicly flagging fake news were regularly ineffective and appeared to be having minimal impact in some cases In journalists working as fact checkers for Facebook criticized the partnership stating that it had produced minimal results and that the company had ignored their concerns br br br Incitement of violence in Sri Lanka br In March the government of Sri Lanka blocked Facebook and other social media services in an effort to quell the violence in the anti Muslim riots with Harsha de Silva the Deputy Minister for National Policies and Economic Affairs tweeting Hate speech on Facebook is increasing beyond acceptable levels Government will have to act immediately to save lives Sri Lankan telecommunications minister Harin Fernando stated that Facebook had been too slow in removing content and banning users who were using its platforms to facilitate violence during the riots In response Facebook stated that it had increased the number of Sinhalese speakers it employs to review content br In April during the aftermath of the Easter bombings the Sri Lankan government blocked access to Facebook Instagram and WhatsApp in an effort to stop the spread of misinformation that could lead to further violence br br br Inclusion of Breitbart News as trusted news source br In October Facebook announced that Breitbart News an American far right news and opinion website would be included as a trusted source in its Facebook News feature alongside sources like The New York Times and The Washington Post The decision sparked controversy due to Breitbart News s status as a platform for the alt right and its reputation for publishing misinformation In October The Wall Street Journal reported that Facebook executives resisted removing Breitbart News from Facebook s News Tab feature to avoid angering Donald Trump and Republican members of Congress despite criticism from Facebook employees An August internal Facebook study had found that Breitbart News was the least trusted news source and also ranked as low quality in the sources it looked at across the U S and Great Britain br br br Disinformation regarding Persecution of Uyghurs br In February a Press Gazette investigation found that Facebook had accepted promotional content from Chinese state media outlets such as China Daily and China Global Television Network that spread disinformation denying the persecution of Uyghurs in China br br br Incitement of human rights abuses in Myanmar br br The chairman of the U N Independent International Fact Finding Mission on Myanmar stated that Facebook played a determining role in the Rohingya genocide Facebook has been accused of enabling the spread of Islamophobic content which targets the Rohingya people The United Nations Human Rights Council has called the platform a useful instrument for those seeking to spread hate br The internet org initiative was brought to Myanmar in Myanmar s relatively recent democratic transition did not provide the country with substantial time to form professional and reliable media outlets free from government intervention Furthermore approximately of Myanmar s residents had internet access before internet org As a result Facebook was the primary source of information and without verifiable professional media options Facebook became a breeding ground for hate speech and disinformation Rumors circulating among family or friends networks on Facebook were perceived as indistinguishable from verified news by its users Frequent anti Rohingya sentiments included high Muslim birthrates increasing economic influence and plans to takeover the country Myanmar s Facebook community was also nearly completely unmonitored by Facebook who at the time only had two Burmese speaking employees br In response Facebook removed accounts which were owned by the Myanmar Armed Forces because they had previously used Facebook to incite hatred against the Rohingya people and they were currently engaging in coordinated inauthentic behavior In February Facebook banned the Myanmar military from its platform and set up rules to ban Tatmadaw linked businesses br The Myanmar military was not the only account found to have incited violence In a review undertaken by Facebook in Facebook banned accounts and pages associated with Myanmar military personnel that were indicated by the UN as being directly responsible for the ethnic cleansing in Rakhine The banned accounts had a widespread reach in the country as they were followed by nearly million accounts which is about half of all Myanmar s Facebook users br On December approximately a hundred Rohingya refugees launched a billion lawsuit against Facebook alleging that it did not do enough to prevent the proliferation of anti Rohingya hate speech because it was interested in prioritizing engagement On December sixteen Rohingya youth living in Cox s Bazar refugee camp made a complaint against Facebook to the Irish National Contact Point for the OECD Guidelines for Multinational Enterprises alleging that Facebook had violated the guidelines and owed them a remedy The lead complainants in the case included members of Rohingya civil society group Arakan Rohingya Society for Peace and Human Rights ARSPH Mohibullah who founded ARSPH and had spearheaded efforts amongst camp based Rohingya refugees to hold Facebook accountable had been murdered just over two months before br On December hundreds of students from various universities in Aceh Indonesia such as Abulyatama University Bina Bangsa Getsempena University and University of Muhammadiyah Aceh stormed a shelter for Rohingya refugees and forced them out of a convention centre in the city of Banda Aceh demanding they be deported The students were seen kicking the belongings of the Rohingya men women and children who were seated on the floor and crying in fear They were also seen burning tyres and chanting various anti Rohingya slogans The protest was believed to be caused by Facebook due to anti Rohingya sentiments that spread through the app br br br Blue tick br Facebook grants blue tick to verified accounts of public personalities brands and celebrities including politicians and artists They have no policy in the cases where an individual who has a verified blue tick account is convicted in a serious criminal case There was a case in India where a politician was convicted and sentenced to years in jail in a serious bribery criminal case but his Facebook page still continued to be verified br br br Neo Nazi and white supremacist content br From circa until March Facebook s internal policy was to permit white nationalist content but not white supremacist content despite advice stating there is no distinction In practice it hosted much white supremacist and neo Nazi content On March Facebook backtracked and stated that white nationalism cannot be meaningfully separated from white supremacy and organized hate groups br In the Centre for Countering Digital Hate CCDH found Facebook was hosting a white supremacist network with more than followers and links to the UK far right The CCDH said Facebook s leadership endangered public safety by letting neo Nazis finance their activities through Facebook and Instagram Facebook was first told about this problem two years ago and failed to act br br br COVID misinformation br br In February the Taiwanese Central News Agency reported that large amounts of misinformation had appeared on Facebook claiming the pandemic in Taiwan was out of control the Taiwanese government had covered up the total number of cases and that President Tsai Ing wen had been infected The Taiwan fact checking organization had suggested the misinformation on Facebook shared similarities with mainland China due to its use of simplified Chinese characters and mainland China vocabulary The organization warned that the purpose of the misinformation is to attack the government The Epoch Times an anti Chinese Communist Party CCP newspaper affiliated with Falun Gong has spread misinformation related to the COVID pandemic in print and via social media including Facebook and YouTube br In April rumors circulated on Facebook alleging that the US Government had just discovered and arrested Charles Lieber chair of the Chemistry and Chemical Biology Department at Harvard University for manufacturing and selling the novel coronavirus COVID to China According to a report from Reuters posts spreading the rumor were shared in multiple languages over times on Facebook br In January the Bureau of Investigative Journalism found that Facebook pages being followed by million people were spreading false information about COVID or vaccinations This was despite a promise by Facebook in that no user or company should directly profit from false information about immunization against COVID A Facebook spokesman said the company had removed a small number of the pages shared with us for violating our policies In August Facebook said that an article raising concerns about potentially fatal effects of a COVID vaccine was the top performing link in the United States between January and March and that another site publishing COVID misinformation was among its top visited pages br br br Marketplace illegal Amazon rainforest sales br In February BBC investigations revealed that Amazon rainforest plots on land reserved for indigenous people were being illegally traded on the Facebook Marketplace with the sellers admitting they do not have the land title The BBC reported that Facebook were ready to work with local authorities but were unwilling to take independent action br br br Incitement of ethnic massacres in Ethiopia br In February Facebook was accused by the Bureau of Investigative Journalism and The Observer of letting activists incite ethnic massacres in the Tigray War by spreading hate and misinformation Following the report a lawsuit against Meta was filed in December in the High Court of Kenya by the son of a Tigrayan academic murdered in November after receiving racist attacks on the platform br br br See also br br Censorship by Facebook br Criticism of Facebook br br br 