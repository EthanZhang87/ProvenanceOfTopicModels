title: Memory management
id: 66924
Memory management is a form of resource management applied to computer memory The essential requirement of memory management is to provide ways to dynamically allocate portions of memory to programs at their request and free it for reuse when no longer needed This is critical to any advanced computer system where more than a single process might be underway at any time br Several methods have been devised that increase the effectiveness of memory management Virtual memory systems separate the memory addresses used by a process from actual physical addresses allowing separation of processes and increasing the size of the virtual address space beyond the available amount of RAM using paging or swapping to secondary storage The quality of the virtual memory manager can have an extensive effect on overall system performance The system allows a computer to appear as if it may have more memory available than physically present thereby allowing multiple processes to share it br In some operating systems e g OS and successors memory is managed by the operating system In other operating systems e g Unix like operating systems memory is managed at the application level br Memory management within an address space is generally categorized as either manual memory management or automatic memory management br br br Manual memory management br br The task of fulfilling an allocation request consists of locating a block of unused memory of sufficient size Memory requests are satisfied by allocating portions from a large pool of memory called the heap or free store At any given time some parts of the heap are in use while some are free unused and thus available for future allocations br In the C language the function which allocates memory from the heap is called malloc and the function which takes previously allocated memory and marks it as free to be used by future allocations is called free br Several issues complicate the implementation such as external fragmentation which arises when there are many small gaps between allocated memory blocks which invalidates their use for an allocation request The allocator s metadata can also inflate the size of individually small allocations This is often managed by chunking The memory management system must track outstanding allocations to ensure that they do not overlap and that no memory is ever lost i e that there are no memory leaks br br br Efficiency br The specific dynamic memory allocation algorithm implemented can impact performance significantly A study conducted in by Digital Equipment Corporation illustrates the overheads involved for a variety of allocators The lowest average instruction path length required to allocate a single memory slot was as measured with an instruction level profiler on a variety of software br br br Implementations br Since the precise location of the allocation is not known in advance the memory is accessed indirectly usually through a pointer reference The specific algorithm used to organize the memory area and allocate and deallocate chunks is interlinked with the kernel and may use any of the following methods br br br Fixed size blocks allocation br br Fixed size blocks allocation also called memory pool allocation uses a free list of fixed size blocks of memory often all of the same size This works well for simple embedded systems where no large objects need to be allocated but suffers from fragmentation especially with long memory addresses However due to the significantly reduced overhead this method can substantially improve performance for objects that need frequent allocation and deallocation and so it is often used in video games br br br Buddy blocks br br In this system memory is allocated into several pools of memory instead of just one where each pool represents blocks of memory of a certain power of two in size or blocks of some other convenient size progression All blocks of a particular size are kept in a sorted linked list or tree and all new blocks that are formed during allocation are added to their respective memory pools for later use If a smaller size is requested than is available the smallest available size is selected and split One of the resulting parts is selected and the process repeats until the request is complete When a block is allocated the allocator will start with the smallest sufficiently large block to avoid needlessly breaking blocks When a block is freed it is compared to its buddy If they are both free they are combined and placed in the correspondingly larger sized buddy block list br br br Slab allocation br br This memory allocation mechanism preallocates memory chunks suitable to fit objects of a certain type or size These chunks are called caches and the allocator only has to keep track of a list of free cache slots Constructing an object will use any one of the free cache slots and destructing an object will add a slot back to the free cache slot list This technique alleviates memory fragmentation and is efficient as there is no need to search for a suitable portion of memory as any open slot will suffice br br br Stack allocation br br Many Unix like systems as well as Microsoft Windows implement a function called alloca for dynamically allocating stack memory in a way similar to the heap based malloc A compiler typically translates it to inlined instructions manipulating the stack pointer Although there is no need of manually freeing memory allocated this way as it is automatically freed when the function that called alloca returns there exists a risk of overflow And since alloca is an ad hoc expansion seen in many systems but never in POSIX or the C standard its behavior in case of a stack overflow is undefined br A safer version of alloca called malloca which reports errors exists on Microsoft Windows It requires the use of freea gnulib provides an equivalent interface albeit instead of throwing an SEH exception on overflow it delegates to malloc when an overlarge size is detected A similar feature can be emulated using manual accounting and size checking such as in the uses of alloca account in glibc br br br Automated memory management br The proper management of memory in an application is a difficult problem and several different strategies for handling memory management have been devised br br br Automatic management of call stack variables br br In many programming language implementations the runtime environment for the program automatically allocates memory in the call stack for non static local variables of a subroutine called automatic variables when the subroutine is called and automatically releases that memory when the subroutine is exited Special declarations may allow local variables to retain values between invocations of the procedure or may allow local variables to be accessed by other subroutines The automatic allocation of local variables makes recursion possible to a depth limited by available memory br br br Garbage collection br br Garbage collection is a strategy for automatically detecting memory allocated to objects that are no longer usable in a program and returning that allocated memory to a pool of free memory locations This method is in contrast to manual memory management where a programmer explicitly codes memory requests and memory releases in the program While automatic garbage collection has the advantages of reducing programmer workload and preventing certain kinds of memory allocation bugs garbage collection does require memory resources of its own and can compete with the application program for processor time br br br Reference counting br br Reference counting is a strategy for detecting that memory is no longer usable by a program by maintaining a counter for how many independent pointers point to the memory Whenever a new pointer points to a piece of memory the programmer is supposed to increase the counter When the pointer changes where it points or when the pointer is no longer pointing to anything or has itself been freed the counter should decrease When the counter drops to zero the memory should be considered unused and freed Some reference counting systems require programmer involvement and some are implemented automatically by the compiler A disadvantage of reference counting is that circular references can develop which cause a memory leak to occur This can be mitigated by either adding the concept of a weak reference a reference that does not participate in reference counting but is notified when the thing it is pointing to is no longer valid or by combining reference counting and garbage collection together br br br Memory pools br br A memory pool is a technique of automatically deallocating memory based on the state of the application such as the lifecycle of a request or transaction The idea is that many applications execute large chunks of code which may generate memory allocations but that there is a point in execution where all of those chunks are known to be no longer valid For example in a web service after each request the web service no longer needs any of the memory allocated during the execution of the request Therefore rather than keeping track of whether or not memory is currently being referenced the memory is allocated according to the request or lifecycle stage with which it is associated When that request or stage has passed all associated memory is deallocated simultaneously br br br Systems with virtual memory br br Virtual memory is a method of decoupling the memory organization from the physical hardware The applications operate on memory via virtual addresses Each attempt by the application to access a particular virtual memory address results in the virtual memory address being translated to an actual physical address In this way the addition of virtual memory enables granular control over memory systems and methods of access br In virtual memory systems the operating system limits how a process can access the memory This feature called memory protection can be used to disallow a process to read or write to memory that is not allocated to it preventing malicious or malfunctioning code in one program from interfering with the operation of another br Even though the memory allocated for specific processes is normally isolated processes sometimes need to be able to share information Shared memory is one of the fastest techniques for inter process communication br Memory is usually classified by access rate into primary storage and secondary storage Memory management systems among other operations also handle the moving of information between these two levels of memory br br br Memory management in OS and successors br IBM System does not support virtual memory Memory isolation of jobs is optionally accomplished using protection keys assigning storage for each job a different key for the supervisor or Memory management in OS is a supervisor function Storage is requested using the GETMAIN macro and freed using the FREEMAIN macro which result in a call to the supervisor SVC to perform the operation br In OS the details vary depending on how the system is generated e g for PCP MFT MVT br In OS MVT suballocation within a job s region or the shared System Queue Area SQA is based on subpools areas a multiple of KB in size the size of an area protected by a protection key Subpools are numbered Within a region subpools are assigned either the job s storage protection or the supervisor s key key Subpools receive the job s key Initially only subpool zero is created and all user storage requests are satisfied from subpool unless another is specified in the memory request Subpools are created by memory requests by the supervisor on behalf of the job Most of these are assigned key although a few get the key of the job Subpool numbers are also relevant in MFT although the details are much simpler MFT uses fixed partitions redefinable by the operator instead of dynamic regions and PCP has only a single partition br Each subpool is mapped by a list of control blocks identifying allocated and free memory blocks within the subpool Memory is allocated by finding a free area of sufficient size or by allocating additional blocks in the subpool up to the region size of the job It is possible to free all or part of an allocated memory area br The details for OS VS are similar to those for MFT and for MVT the details for OS VS are similar to those for MVT except that the page size is KiB For both OS VS and OS VS the shared System Queue Area SQA is nonpageable br In MVS the address space includes an additional pageable shared area the Common Storage Area CSA and two additional private areas the nonpageable local system queue area LSQA and the pageable System Work area SWA Also the storage keys are all reserved for use by privileged code br br br See also br Dynamic array br Out of memory br Heap pollution br br br Notes br br br br br br Bibliography br Donald Knuth Fundamental Algorithms Third Edition Addison Wesley ISBN Section Dynamic Storage Allocation pp br Simple Memory Allocation AlgorithmsArchived March at the Wayback Machine originally published on OSDEV Community br Wilson P R Johnstone M S Neely M Boles D Dynamic storage allocation A survey and critical review Memory Management Lecture Notes in Computer Science Vol pp CiteSeerX doi ISBN br Berger E D Zorn B G McKinley K S June Composing High Performance Memory Allocators PDF Proceedings of the ACM SIGPLAN conference on Programming language design and implementation PLDI pp CiteSeerX doi ISBN S CID br Berger E D Zorn B G McKinley K S November Reconsidering Custom Memory Allocation PDF Proceedings of the th ACM SIGPLAN conference on Object oriented programming systems languages and applications OOPSLA pp CiteSeerX doi ISBN S CID br Wilson Paul R Johnstone Mark S Neely Michael Boles David September Dynamic Storage Allocation A Survey and Critical Review PDF Austin Texas Department of Computer Sciences University of Texas retrieved br OS Sup br OS Release IBM System Operating System Supervisor Services and Macro Instructions PDF IBM Systems Reference Library Eighth ed IBM September GC br OSVS Dig br OS VS Programmer s Reference Digest Release PDF Systems Sixth ed IBM September GC with TNLs br br br External links br br Generic Memory Manager C library br Sample bit mapped arena memory allocator in C br TLSF a constant time allocator for real time systems br Slides on Dynamic memory allocation br Inside A Storage Allocator br The Memory Management Reference br The Memory Management Reference Beginner s Guide Allocation br Linux Memory Management br Memory Management For System Programmers Archived at the Wayback Machine br VMem general malloc free replacement Fast thread safe C allocator br Operating System Memory Management