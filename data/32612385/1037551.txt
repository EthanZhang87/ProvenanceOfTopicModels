title: Disjoint-set data structure
id: 1037551
In computer science a disjoint set data structure also called a union find data structure or merge find set is a data structure that stores a collection of disjoint non overlapping sets Equivalently it stores a partition of a set into disjoint subsets It provides operations for adding new sets merging sets replacing them by their union and finding a representative member of a set The last operation makes it possible to find out efficiently if any two elements are in the same or different sets br While there are several ways of implementing disjoint set data structures in practice they are often identified with a particular implementation called a disjoint set forest This is a specialized type of forest which performs unions and finds in near constant amortized time To perform a sequence of m addition union or find operations on a disjoint set forest with n nodes requires total time O m n where n is the extremely slow growing inverse Ackermann function Disjoint set forests do not guarantee this performance on a per operation basis Individual union and find operations can take longer than a constant times n time but each operation causes the disjoint set forest to adjust itself so that successive operations are faster Disjoint set forests are both asymptotically optimal and practically efficient br Disjoint set data structures play a key role in Kruskal s algorithm for finding the minimum spanning tree of a graph The importance of minimum spanning trees means that disjoint set data structures underlie a wide variety of algorithms In addition disjoint set data structures also have applications to symbolic computation as well as in compilers especially for register allocation problems br br br History br Disjoint set forests were first described by Bernard A Galler and Michael J Fischer in In their time complexity was bounded to br br br br O br br br log br br br br br br br n br br br br br displaystyle O log n br br the iterated logarithm of br br br br n br br br displaystyle n br br by Hopcroft and Ullman In Robert Tarjan was the first to prove the br br br br O br br m br br br n br br br br br displaystyle O m alpha n br br inverse Ackermann function upper bound on the algorithm s time complexity He also proved it to be tight In he showed that this was the lower bound for a certain class of algorithms that include the Galler Fischer structure In Fredman and Saks showed that br br br br br br br br n br br br br br displaystyle Omega alpha n br br amortized words of br br br br O br br log br br n br br br br displaystyle O log n br br bits must be accessed by any disjoint set data structure per operation thereby proving the optimality of the data structure in this model br In Galil and Italiano published a survey of data structures for disjoint sets br In Richard J Anderson and Heather Woll described a parallelized version of Union Find that never needs to block br In Sylvain Conchon and Jean Christophe Filli tre developed a semi persistent version of the disjoint set forest data structure and formalized its correctness using the proof assistant Coq Semi persistent means that previous versions of the structure are efficiently retained but accessing previous versions of the data structure invalidates later ones Their fastest implementation achieves performance almost as efficient as the non persistent algorithm They do not perform a complexity analysis br Variants of disjoint set data structures with better performance on a restricted class of problems have also been considered Gabow and Tarjan showed that if the possible unions are restricted in certain ways then a truly linear time algorithm is possible br br br Representation br Each node in a disjoint set forest consists of a pointer and some auxiliary information either a size or a rank but not both The pointers are used to make parent pointer trees where each node that is not the root of a tree points to its parent To distinguish root nodes from others their parent pointers have invalid values such as a circular reference to the node or a sentinel value Each tree represents a set stored in the forest with the members of the set being the nodes in the tree Root nodes provide set representatives Two nodes are in the same set if and only if the roots of the trees containing the nodes are equal br Nodes in the forest can be stored in any way convenient to the application but a common technique is to store them in an array In this case parents can be indicated by their array index Every array entry requires log n bits of storage for the parent pointer A comparable or lesser amount of storage is required for the rest of the entry so the number of bits required to store the forest is n log n If an implementation uses fixed size nodes thereby limiting the maximum size of the forest that can be stored then the necessary storage is linear in n br br br Operations br Disjoint set data structures support three operations Making a new set containing a new element Finding the representative of the set containing a given element and Merging two sets br br br Making new sets br The MakeSet operation adds a new element into a new set containing only the new element and the new set is added to the data structure If the data structure is instead viewed as a partition of a set then the MakeSet operation enlarges the set by adding the new element and it extends the existing partition by putting the new element into a new subset containing only the new element br In a disjoint set forest MakeSet initializes the node s parent pointer and the node s size or rank If a root is represented by a node that points to itself then adding an element can be described using the following pseudocode br br function MakeSet x is br if x is not already in the forest then br x parent x br x size if nodes store size br x rank if nodes store rank br end if br end function br br This operation has constant time complexity In particular initializing a br disjoint set forest with n nodes requires O n br time br Lack of a parent assigned to the node implies that the node is not present in the forest br In practice MakeSet must be preceded by an operation that allocates memory to hold x As long as memory allocation is an amortized constant time operation as it is for a good dynamic array implementation it does not change the asymptotic performance of the random set forest br br br Finding set representatives br The Find operation follows the chain of parent pointers from a specified query node x until it reaches a root element This root element represents the set to which x belongs and may be x itself Find returns the root element it reaches br Performing a Find operation presents an important opportunity for improving the forest The time in a Find operation is spent chasing parent pointers so a flatter tree leads to faster Find operations When a Find is executed there is no faster way to reach the root than by following each parent pointer in succession However the parent pointers visited during this search can be updated to point closer to the root Because every element visited on the way to a root is part of the same set this does not change the sets stored in the forest But it makes future Find operations faster not only for the nodes between the query node and the root but also for their descendants This updating is an important part of the disjoint set forest s amortized performance guarantee br There are several algorithms for Find that achieve the asymptotically optimal time complexity One family of algorithms known as path compression makes every node between the query node and the root point to the root Path compression can be implemented using a simple recursion as follows br br function Find x is br if x parent x then br x parent Find x parent br return x parent br else br return x br end if br end function br br This implementation makes two passes one up the tree and one back down It requires enough scratch memory to store the path from the query node to the root in the above pseudocode the path is implicitly represented using the call stack This can be decreased to a constant amount of memory by performing both passes in the same direction The constant memory implementation walks from the query node to the root twice once to find the root and once to update pointers br br function Find x is br root x br while root parent root do br root root parent br end while br br while x parent root do br parent x parent br x parent root br x parent br end while br br return root br end function br br Tarjan and Van Leeuwen also developed one pass Find algorithms that retain the same worst case complexity but are more efficient in practice These are called path splitting and path halving Both of these update the parent pointers of nodes on the path between the query node and the root Path splitting replaces every parent pointer on that path by a pointer to the node s grandparent br br function Find x is br while x parent x do br x x parent x parent x parent parent br end while br return x br end function br br Path halving works similarly but replaces only every other parent pointer br br function Find x is br while x parent x do br x parent x parent parent br x x parent br end while br return x br end function br br br Merging two sets br br The operation Union x y replaces the set containing x and the set containing y with their union Union first uses Find to determine the roots of the trees containing x and y If the roots are the same there is nothing more to do Otherwise the two trees must be merged This is done by either setting the parent pointer of x s root to y s or setting the parent pointer of y s root to x s br The choice of which node becomes the parent has consequences for the complexity of future operations on the tree If it is done carelessly trees can become excessively tall For example suppose that Union always made the tree containing x a subtree of the tree containing y Begin with a forest that has just been initialized with elements br br br br br br br br br br br br n br br br br displaystyle ldots n br br and execute Union Union Union n n The resulting forest contains a single tree whose root is n and the path from to n passes through every node in the tree For this forest the time to run Find is O n br In an efficient implementation tree height is controlled using union by size or union by rank Both of these require a node to store information besides just its parent pointer This information is used to decide which root becomes the new parent Both strategies ensure that trees do not become too deep br br br Union by size br In the case of union by size a node stores its size which is simply its number of descendants including the node itself When the trees with roots x and y are merged the node with more descendants becomes the parent If the two nodes have the same number of descendants then either one can become the parent In both cases the size of the new parent node is set to its new total number of descendants br br function Union x y is br Replace nodes by roots br x Find x br y Find y br br if x y then br return x and y are already in the same set br end if br br If necessary swap variables to ensure that br x has at least as many descendants as y br if x size y size then br x y y x br end if br br Make x the new root br y parent x br Update the size of x br x size x size y size br end function br br The number of bits necessary to store the size is clearly the number of bits necessary to store n This adds a constant factor to the forest s required storage br br br Union by rank br For union by rank a node stores its rank which is an upper bound for its height When a node is initialized its rank is set to zero To merge trees with roots x and y first compare their ranks If the ranks are different then the larger rank tree becomes the parent and the ranks of x and y do not change If the ranks are the same then either one can become the parent but the new parent s rank is incremented by one While the rank of a node is clearly related to its height storing ranks is more efficient than storing heights The height of a node can change during a Find operation so storing ranks avoids the extra effort of keeping the height correct In pseudocode union by rank is br br function Union x y is br Replace nodes by roots br x Find x br y Find y br br if x y then br return x and y are already in the same set br end if br br If necessary rename variables to ensure that br x has rank at least as large as that of y br if x rank y rank then br x y y x br end if br br Make x the new root br y parent x br If necessary increment the rank of x br if x rank y rank then br x rank x rank br end if br end function br br It can be shown that every node has rank br br br br br log br br n br br br br displaystyle lfloor log n rfloor br br or less Consequently each rank can be stored in O log log n bits and all the ranks can be stored in O n log log n bits This makes the ranks an asymptotically negligible portion of the forest s size br It is clear from the above implementations that the size and rank of a node do not matter unless a node is the root of a tree Once a node becomes a child its size and rank are never accessed again br br br Time complexity br A disjoint set forest implementation in which Find does not update parent pointers and in which Union does not attempt to control tree heights can have trees with height O n In such a situation the Find and Union operations require O n time br If an implementation uses path compression alone then a sequence of n MakeSet operations followed by up to n Union operations and f Find operations has a worst case running time of br br br br br br n br br f br br br br br br br br log br br br br f br br br br n br br br br n br br br br br br br displaystyle Theta n f cdot left log f n n right br br br Using union by rank but without updating parent pointers during Find gives a running time of br br br br br br m br log br br n br br br br displaystyle Theta m log n br br for m operations of any type up to n of which are MakeSet operations br The combination of path compression splitting or halving with union by size or by rank reduces the running time for m operations of any type up to n of which are MakeSet operations to br br br br br br m br br br n br br br br br displaystyle Theta m alpha n br br This makes the amortized running time of each operation br br br br br br br br n br br br br br displaystyle Theta alpha n br br This is asymptotically optimal meaning that every disjoint set data structure must use br br br br br br br br n br br br br br displaystyle Omega alpha n br br amortized time per operation Here the function br br br br br br n br br br br displaystyle alpha n br br is the inverse Ackermann function The inverse Ackermann function grows extraordinarily slowly so this factor is or less for any n that can actually be written in the physical universe This makes disjoint set operations practically amortized constant time br br br Proof of O m log n time complexity of Union Find br The precise analysis of the performance of a disjoint set forest is somewhat intricate However there is a much simpler analysis that proves that the amortized time for any m Find or Union operations on a disjoint set forest containing n objects is O m log n where log denotes the iterated logarithm br Lemma As the find function follows the path along to the root the rank of node it encounters is increasing br br Lemma A node u which is root of a subtree with rank r has at least br br br br br br br r br br br br br displaystyle r br br nodes br br Lemma The maximum number of nodes of rank r is at most br br br br br br n br br br br r br br br br br br br br displaystyle frac n r br br br For convenience we define bucket here a bucket is a set that contains vertices with particular ranks br We create some buckets and put vertices into the buckets according to their ranks inductively That is vertices with rank go into the zeroth bucket vertices with rank go into the first bucket vertices with ranks and go into the second bucket If the B th bucket contains vertices with ranks from interval br br br br br br br r br br br br br r br br br br br br br br br br r br br R br br br br br br displaystyle left r r right r R br br then the B st bucket will contain vertices with ranks from interval br br br br br br br R br br br br br R br br br br br br br br br br br displaystyle left R R right br br br We can make two observations about the buckets br br The total number of buckets is at most log n br Proof When we go from one bucket to the next we add one more two to the power that is the next bucket to br br br br br br br B br br br br br B br br br br br br br br br br displaystyle left B B right br br will be br br br br br br br br br br B br br br br br br br br br br B br br br br br br br br br br br br displaystyle left B B right br br br The maximum number of elements in bucket br br br br br br br B br br br br br B br br br br br br br br br br displaystyle left B B right br br is at most br br br br br br br br n br br br br br B br br br br br br br displaystyle frac n B br br br Proof The maximum number of elements in bucket br br br br br br br B br br br br br B br br br br br br br br br br displaystyle left B B right br br is at most br br br br br br n br br br br B br br br br br br br br n br br br br B br br br br br br br br br br n br br br br B br br br br br br br br br br br br n br br br br br br br B br br br br br br br br br br br br br br n br br br br br B br br br br br br br br displaystyle frac n B frac n B frac n B cdots frac n B leq frac n B br br br Let F represent the list of find operations performed and let br br br br br br T br br br br br br br br br F br br br br link to the root br br br br displaystyle T sum F text link to the root br br br br br br br T br br br br br br br br br F br br br br number of links traversed where the buckets are different br br br br displaystyle T sum F text number of links traversed where the buckets are different br br br br br br br T br br br br br br br br br F br br br br number of links traversed where the buckets are the same br br br br displaystyle T sum F text number of links traversed where the buckets are the same br br br Then the total cost of m finds is br br br br T br br br T br br br br br br br T br br br br br br br T br br br br br br br br displaystyle T T T T br br br Since each find operation makes exactly one traversal that leads to a root we have T O m br Also from the bound above on the number of buckets we have T O mlog n br For T suppose we are traversing an edge from u to v where u and v have rank in the bucket B B and v is not the root at the time of this traversing otherwise the traversal would be accounted for in T Fix u and consider the sequence br br br br br v br br br br br br br v br br br br br br br br br v br br k br br br br br displaystyle v v ldots v k br br that take the role of v in different find operations Because of path compression and not accounting for the edge to a root this sequence contains only different nodes and because of Lemma we know that the ranks of the nodes in this sequence are strictly increasing By both of the nodes being in the bucket we can conclude that the length k of the sequence the number of times node u is attached to a different root in the same bucket is at most the number of ranks in the buckets B that is at most br br br br br br br B br br br br br br B br br br br br B br br br br br br displaystyle B B B br br br Therefore br br br br br T br br br br br br br br br br B br br br br br B br br br br br br br br br br br u br br br br br br B br br br br br br displaystyle T leq sum B B sum u B br br br From Observations and we can conclude that br br br br br T br br br br br br br br br B br br br br br br B br br br br br br br n br br br br br B br br br br br br br n br br log br br br br br br n br br br br textstyle T leq sum B B frac n B leq n log n br br br Therefore br br br br T br br br T br br br br br br br T br br br br br br br T br br br br br br O br br m br br log br br br br br br n br br br br br displaystyle T T T T O m log n br br br br Other structures br br br Better worst case time per operation br The worst case time of the Find operation in trees with Union by rank or Union by weight is br br br br br br log br br n br br br br displaystyle Theta log n br br i e it is br br br br O br br log br br n br br br br displaystyle O log n br br and this bound is tight br In N Blum gave an implementation of the operations that does not use path compression but compresses trees during br br br br u br n br i br o br n br br br displaystyle union br br His implementation runs in br br br br O br br log br br n br br br br log br br log br br n br br br br displaystyle O log n log log n br br time per operation and thus in comparison with Galler and Fischer s structure it has a better worst case time per operation but inferior amortized time In Alstrup et al gave a structure that has optimal worst case br time br br br br O br br log br br n br br br br log br br log br br n br br br br displaystyle O log n log log n br br together with inverse Ackermann amortized time br br br Deletion br The regular implementation as disjoint set forests does not react favorably to the deletion of elements br in the sense that the time for Find will not improve as a result of the decrease in the number of elements However there exist modern implementations that allow for constant time deletion and where the time bound for Find depends on the current number of elements br br br Applications br br Disjoint set data structures model the partitioning of a set for example to keep track of the connected components of an undirected graph This model can then be used to determine whether two vertices belong to the same component or whether adding an edge between them would result in a cycle The Union Find algorithm is used in high performance implementations of unification br This data structure is used by the Boost Graph Library to implement its Incremental Connected Components functionality It is also a key component in implementing Kruskal s algorithm to find the minimum spanning tree of a graph br The Hoshen Kopelman algorithm uses a Union Find in the algorithm br br br See also br Partition refinement a different data structure for maintaining disjoint sets with updates that split sets apart rather than merging them together br Dynamic connectivity br br br br br br External links br C implementation part of the Boost C libraries br Java implementation part of JGraphT library br Javascript implementation br Python implementation